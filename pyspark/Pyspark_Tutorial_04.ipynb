{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf039b33",
   "metadata": {},
   "source": [
    "## GroupBy and Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d56ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Tutorial_04').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48720f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.25:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Tutorial_04</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb982d67640>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b81b432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get all files in my directory\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def get_file_from_directory(folder_dir='', file_name=''):\n",
    "    filtered_list = []\n",
    "    file_list = []\n",
    "\n",
    "    try:\n",
    "        if folder_dir != '':\n",
    "            file_list = [f for f in listdir(folder_dir) if isfile(join(folder_dir, f))]\n",
    "\n",
    "        if file_name != '':\n",
    "            for arquivo in file_list:\n",
    "                if file_name in arquivo:\n",
    "                    filtered_list.append(file_name)\n",
    "        else:\n",
    "            return 'Insera o nome do arquivo a ser localizado!'\n",
    "        \n",
    "    except FileNotFoundError as error:\n",
    "        print(f\"Insira um caminho valido para a pasta de arquivos! \\n Error: {error.filename}\")\n",
    "        \n",
    "    except IndexError as index_error:\n",
    "        print(f\"Arquivo não localozado {index_error}, certifique-se de inserir o nome do arquivo.\")\n",
    "        \n",
    "    try:\n",
    "        return (f\"{folder_dir}/{filtered_list[0]}\", 'arquivo não localizado')[len(filtered_list) == 0]\n",
    "    \n",
    "    except IndexError:\n",
    "        return 'Arquivo não localizado, talvez o nome do arquivo ou pasta esteja errado.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3a2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set var values\n",
    "folder='/home/toni/dev_spark/notebooks/files'\n",
    "csv_file = 'sales_data_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ad8b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_pyspark=spark.read.csv(get_file_from_directory(folder,csv_file), header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66de5c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ORDERNUMBER: integer (nullable = true)\n",
      " |-- QUANTITYORDERED: integer (nullable = true)\n",
      " |-- PRICEEACH: double (nullable = true)\n",
      " |-- ORDERLINENUMBER: integer (nullable = true)\n",
      " |-- SALES: double (nullable = true)\n",
      " |-- ORDERDATE: string (nullable = true)\n",
      " |-- STATUS: string (nullable = true)\n",
      " |-- QTR_ID: integer (nullable = true)\n",
      " |-- MONTH_ID: integer (nullable = true)\n",
      " |-- YEAR_ID: integer (nullable = true)\n",
      " |-- PRODUCTLINE: string (nullable = true)\n",
      " |-- MSRP: integer (nullable = true)\n",
      " |-- PRODUCTCODE: string (nullable = true)\n",
      " |-- CUSTOMERNAME: string (nullable = true)\n",
      " |-- PHONE: string (nullable = true)\n",
      " |-- ADDRESSLINE1: string (nullable = true)\n",
      " |-- ADDRESSLINE2: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- POSTALCODE: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- TERRITORY: string (nullable = true)\n",
      " |-- CONTACTLASTNAME: string (nullable = true)\n",
      " |-- CONTACTFIRSTNAME: string (nullable = true)\n",
      " |-- DEALSIZE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d035f082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|     PRODUCTLINE|        sum(SALES)|\n",
      "+----------------+------------------+\n",
      "|     Motorcycles|1166388.3400000003|\n",
      "|    Vintage Cars|1903150.8399999992|\n",
      "|           Ships|         714437.13|\n",
      "|Trucks and Buses|1127789.8399999996|\n",
      "|    Classic Cars| 3919615.659999997|\n",
      "|          Trains|226243.46999999997|\n",
      "|          Planes| 975003.5700000001|\n",
      "+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Groupby PRODUCTLINE sum\n",
    "sales_pyspark.groupBy('PRODUCTLINE').sum('SALES').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244131e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|     PRODUCTLINE|        avg(SALES)|\n",
      "+----------------+------------------+\n",
      "|     Motorcycles| 3523.831842900303|\n",
      "|    Vintage Cars|3135.3391103789113|\n",
      "|           Ships| 3053.150128205128|\n",
      "|Trucks and Buses|3746.8100996677726|\n",
      "|    Classic Cars|4053.3771044467394|\n",
      "|          Trains|2938.2268831168826|\n",
      "|          Planes|3186.2861764705885|\n",
      "+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Groupby PRODUCTLINE mean\n",
    "sales_pyspark.groupBy('PRODUCTLINE').mean('SALES').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc21f003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|        CITY|        sum(SALES)|\n",
      "+------------+------------------+\n",
      "|   Minato-ku|120562.73999999996|\n",
      "|    Salzburg|         149798.63|\n",
      "|      Madrid|1082551.4400000002|\n",
      "|   Allentown|122138.14000000001|\n",
      "|       Boras|134259.33000000002|\n",
      "|        Lule|          75754.88|\n",
      "|White Plains| 85555.98999999998|\n",
      "|   Singapore|288488.41000000003|\n",
      "|  Manchester|157807.80999999997|\n",
      "|  Brickhaven|165255.20000000004|\n",
      "|   Frankfurt| 85171.58999999998|\n",
      "|Philadelphia|151189.12999999998|\n",
      "|     Stavern|         116599.19|\n",
      "| Los Angeles|          48048.46|\n",
      "|   Cambridge|139243.99999999994|\n",
      "|  Versailles| 64834.32000000001|\n",
      "|       Lille|          69052.41|\n",
      "|        Oslo|          79224.23|\n",
      "|      Nantes|         204304.86|\n",
      "|   Marseille|          74936.14|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Groupby City with maximum value\n",
    "sales_pyspark.groupBy('CITY').sum('SALES').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec5f425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|     PRODUCTLINE|count|\n",
      "+----------------+-----+\n",
      "|     Motorcycles|  331|\n",
      "|    Vintage Cars|  607|\n",
      "|           Ships|  234|\n",
      "|Trucks and Buses|  301|\n",
      "|    Classic Cars|  967|\n",
      "|          Trains|   77|\n",
      "|          Planes|  306|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Groupby PRODUCTLINE count\n",
    "sales_pyspark.groupBy('PRODUCTLINE').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77d4b5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|         sum(SALES)|\n",
      "+-------------------+\n",
      "|1.003262885000001E7|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_pyspark.agg({'SALES':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b3f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
